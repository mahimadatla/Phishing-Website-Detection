{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data\n",
    "df = pd.read_csv(\"phishing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining dataframe \n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NA\n",
    "df.isna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NULL\n",
    "df.isnull()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying that all values are not null\n",
    "df.notnull()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting labels\n",
    "labels = df.loc[:, ~df.columns.str.contains('class')]\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a correlation matrix\n",
    "corr_matrix = labels.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "print(pd.DataFrame(upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant = [1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 18, 23, 24, 25, 28, 30]\n",
    "features = np.array(labels.columns)[relevant]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting target\n",
    "target = df['class']\n",
    "target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "training_labels, testing_labels, training_target, testing_target  = train_test_split(labels, target, random_state = 42, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Define the range of hyperparameters for each classifier\n",
    "param_grid_lr = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 10]\n",
    "}\n",
    "param_grid_dt = {\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [5, 10, 15],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Create a list of classifiers with their corresponding hyperparameters\n",
    "classifiers = [\n",
    "    (LogisticRegression(), param_grid_lr),\n",
    "    (SVC(), param_grid_svc),\n",
    "    (RandomForestClassifier(random_state=42), param_grid_rf),\n",
    "    (GradientBoostingClassifier(random_state=42), param_grid_gb),\n",
    "    (DecisionTreeClassifier(random_state=42), param_grid_dt),\n",
    "    (KNeighborsClassifier(), param_grid_knn),\n",
    "    (GaussianNB(), None),\n",
    "    (AdaBoostClassifier(random_state=42), param_grid_ada),\n",
    "    (LinearDiscriminantAnalysis(), None),\n",
    "    (QuadraticDiscriminantAnalysis(), None)\n",
    "]\n",
    "\n",
    "# Loop over the classifiers and perform grid search\n",
    "for clf, param_grid in classifiers:\n",
    "    if param_grid is not None:\n",
    "        grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "        grid_search.fit(training_labels, training_target)\n",
    "        print(clf.__class__.__name__)\n",
    "        print(\"Best parameters:\", grid_search.best_params_)\n",
    "        print(\"Training accuracy:\", grid_search.best_score_)\n",
    "        print(\"Test accuracy:\", grid_search.score(testing_labels, testing_target))\n",
    "        print(\"---\")\n",
    "    else:\n",
    "        clf.fit(training_labels, training_target)\n",
    "        print(clf.__class__.__name__)\n",
    "        print(\"Training accuracy:\", clf.score(training_labels, training_target))\n",
    "        print(\"Test accuracy:\", clf.score(testing_labels, testing_target))\n",
    "        print(\"---\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populating a list of classifiers with hyperparameters\n",
    "classifiers = [\n",
    "    LogisticRegression(penalty='l1', C=10, solver='liblinear'),\n",
    "    SVC(kernel='rbf', C=1.0, gamma='scale'),\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "    GradientBoostingClassifier(learning_rate=0.1, n_estimators=100, max_depth=5, random_state=42),\n",
    "    DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "    KNeighborsClassifier(n_neighbors=5, weights='uniform'),\n",
    "    GaussianNB(),\n",
    "    AdaBoostClassifier(n_estimators=100, learning_rate=1.0, random_state=42),\n",
    "    LinearDiscriminantAnalysis(solver='svd'),\n",
    "    QuadraticDiscriminantAnalysis()\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store prediction data\n",
    "predictions = {}\n",
    "\n",
    "models = []\n",
    "\n",
    "# Iterating over all classifiers\n",
    "for classifier in classifiers:\n",
    "\n",
    "    # Fitting classifier\n",
    "    classifier.fit(training_labels.values, training_target.values)\n",
    "\n",
    "    # Updating predictions dict\n",
    "    predictions[str(classifier)] = classifier.predict(testing_labels.values)\n",
    "\n",
    "    # Obtaining confusion matrix\n",
    "    cm = confusion_matrix(y_pred= predictions[str(classifier)], y_true = testing_target.values)\n",
    "    models.append(classifier)\n",
    "\n",
    "    # Plotting confusion matrix\n",
    "    ax = plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax=ax, cmap='Blues')\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title(str(classifier))\n",
    "    plt.show()\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining metrics - accuracy, f1, recall, precision\n",
    "\n",
    "metrics = { 'accuracy': [], 'f1' : [], 'recall' : [], 'precision' : []  }\n",
    "for classifier_name, prediction in predictions.items():\n",
    "    metrics['accuracy'].append(accuracy_score(testing_target, prediction))\n",
    "    metrics['f1'].append(f1_score(testing_target, prediction, average='weighted'))\n",
    "    metrics['recall'].append(recall_score(testing_target, prediction, average='weighted'))\n",
    "    metrics['precision'].append(precision_score(testing_target, prediction, average='weighted'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the performance metrics using a bar chart\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = np.arange(len(classifiers))\n",
    "width = 0.2\n",
    "rects1 = ax.bar(x - width*1.5, metrics['accuracy'], width, label='Accuracy')\n",
    "rects2 = ax.bar(x - width*0.5, metrics['precision'], width, label='Precision')\n",
    "rects3 = ax.bar(x + width*0.5, metrics['recall'], width, label='Recall')\n",
    "rects4 = ax.bar(x + width*1.5, metrics['f1'], width, label='F1-score')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classifiers, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Performance metrics of classifiers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame from metrics dictionary\n",
    "performance = pd.DataFrame(metrics)\n",
    "\n",
    "# Adding a column for classifier names\n",
    "performance['Classifier'] = list(predictions.keys())\n",
    "\n",
    "# Reordering columns for better visibility\n",
    "performance = performance[['Classifier', 'accuracy', 'f1', 'recall', 'precision']]\n",
    "\n",
    "# Displaying DataFrame\n",
    "performance.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "for model in models:\n",
    "    joblib.dump(model, f'model/{model.__class__.__name__}.pkl', compress=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models[2].__class__.__name__, models[2].feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store prediction data\n",
    "predictions_train = {}\n",
    "\n",
    "models = []\n",
    "\n",
    "# Iterating over all classifiers\n",
    "for model in models:\n",
    "\n",
    "    # Fitting classifier\n",
    "    # model.fit(training_labels.values, training_target.values)\n",
    "\n",
    "    # Updating predictions dict\n",
    "    predictions[str(classifier)] = classifier.predict(testing_labels.values)\n",
    "\n",
    "    # Obtaining confusion matrix\n",
    "    cm = confusion_matrix(y_pred= predictions[str(classifier)], y_true = testing_target.values)\n",
    "    models.append(classifier)\n",
    "\n",
    "    # Plotting confusion matrix\n",
    "    ax = plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax=ax, cmap='Blues')\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title(str(classifier))\n",
    "    plt.show()\n",
    "\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6879ac9534aa8e54d3e2c9d1f24ea883277559342f01c791ed20d05a45bf3922"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
